{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation d'un RNN pour générer des accords appris sur le realbook.\n",
    "## Implémentation en pytorch à partir de l'implémentation en Keras proposée par keunwoochoi\n",
    "Github du projet de référence https://github.com/keunwoochoi/lstm_real_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition d'une petite fonction utile :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de l'objet RNN :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation de la base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 3531261\n",
      "total chars: 1260\n"
     ]
    }
   ],
   "source": [
    "path = 'chord_sentences.txt' # the txt data source\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chord_seq = text.split(' ')\n",
    "chars = set(chord_seq)\n",
    "text = chord_seq\n",
    "\n",
    "\n",
    "# Création de dictionnaires contenants les noms\n",
    "# des accords contenus dans le realbook\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "num_chars = len(char_indices)\n",
    "print('total chars:', num_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coup d'oeil sur la structure de la base de données : \n",
    "Les morceaux sont repérés par des \"_START_\" et des \"_END_\"\n",
    "\n",
    "Voyez plutôt :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_START_', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'G:9', 'G:9', 'G:9', 'G:9', 'G:9', 'G:9', 'G:9', 'G:9', 'C:9', 'C:9', 'C:9', 'C:9', 'C:7', 'C:7', 'C:7', 'C:7', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:min7', 'F:min7', 'F:min7', 'F:min7', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'G:min7', 'G:min7', 'G:min7', 'G:min7', 'A:7', 'A:7', 'A:7', 'A:7', 'D:9', 'D:9', 'D:9', 'D:9', 'G:9', 'G:9', 'G:9', 'G:9', 'E:min7', 'E:min7', 'G:7', 'G:7', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'A:min7', 'A:min7', 'A:min7', 'A:min7', 'A:min7', 'A:min7', 'A:min7', 'A:min7', 'E:min7', 'E:min7', 'E:min7', 'E:min7', 'E:min7', 'E:min7', 'E:min7', 'E:min7', 'F:maj7', 'F:maj7', 'F:maj7', 'F:maj7', 'F:7', 'F:7', 'F:7', 'F:7', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:7', 'C:7', 'F:maj', 'F:maj', 'F:maj', 'F:maj', 'F:min7', 'F:min7', 'F:min7', 'F:min7', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'A:7', 'A:7', 'A:7', 'A:7', 'D:7', 'D:7', 'D:7', 'D:7', 'D:7', 'D:7', 'G:7', 'G:7', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'G:7', 'G:7', '_END_', '_START_', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'A#:7', 'A#:7', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'G:min', 'G:min', 'G:min', 'G:min', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'A#:7', 'A#:7', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'B:7', 'B:7', 'A#:7', 'A#:7', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'A#:7', 'A#:7', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:maj', 'D#:7', 'D#:7', 'D#:7', 'D#:7', 'G:maj/5', 'G:maj/5', 'G:maj/5', 'G:maj/5', 'G:maj/5', 'G:maj/5', 'D:7', 'D:7', 'G:maj', 'G:maj', 'G:maj', 'G:maj', 'A#:7/5', 'A#:7/5', 'A#:7/5', 'A#:7/5', 'D#:7', 'D#:7', 'D#:7', 'D#:7', 'D#:7']\n"
     ]
    }
   ],
   "source": [
    "#Affichage du début de la base de données\n",
    "print(text[0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Déoupe de la bases de données :\n",
    "On crée ici une liste qui contient des exemples de suite d'accords dont on va se servir pour créer nos vecteurs qui serviront à feed le RNN. \n",
    "Pourquoi ils sont découpés comme ça et pas par morceau ? Je ne sais pas, ça me parait bizare, peut être qu'il faudrait qu'on découpe par morceaux plutôt que de couper en 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 181761\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "\tsentences.append(text[i: i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation des exemples en vecteurs pour les utiliser en entrées et sorties du RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "done\n",
      "X.size() : \n",
      "torch.Size([10000, 20, 1, 1260])\n",
      "Y.size() : \n",
      "torch.Size([10000, 20, 1])\n"
     ]
    }
   ],
   "source": [
    "def vectorize(sentences,maxlen,num_chars,char_indices):\n",
    "    #limiting the dataset size to do fast exemples \n",
    "    max_dataset_lenght = 10000\n",
    "    print('Vectorization...')\n",
    "    len_dataset = min(max_dataset_lenght, len(sentences))\n",
    "    X = torch.zeros(len_dataset, maxlen, 1, num_chars)\n",
    "    Y = torch.zeros((len_dataset, maxlen, 1),dtype = torch.long)\n",
    "    for i, sentence in enumerate(sentences[0:len_dataset]):\n",
    "        for t, char in enumerate(sentence[0:len_dataset]):\n",
    "            X[i, t, 0, char_indices[char]] = 1\n",
    "            Y[i, t, 0] = char_indices[char]\n",
    "    print(\"done\")\n",
    "    print(\"X.size() : \")\n",
    "    print(X.size())\n",
    "    print(\"Y.size() : \")\n",
    "    print(Y.size())\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# text to vectors\n",
    "X, Y = vectorize(sentences,maxlen,num_chars,char_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la fonction train du réseau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_in,Y_out):\n",
    "    #target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(len(X_in) - 1):\n",
    "        output, hidden = rnn(X_in[i], hidden)\n",
    "        l = criterion(output, Y_out[i+1])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item() / X.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du réseau et définition de la boucle d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (5 5%) 0.0135\n",
      "0m 3s (10 10%) 0.0135\n",
      "0m 5s (15 15%) 0.0135\n",
      "0m 6s (20 20%) 0.0135\n",
      "0m 8s (25 25%) 0.0135\n",
      "0m 10s (30 30%) 0.0134\n",
      "0m 11s (35 35%) 0.0134\n",
      "0m 13s (40 40%) 0.0135\n",
      "0m 14s (45 45%) 0.0135\n",
      "0m 16s (50 50%) 0.0134\n",
      "0m 17s (55 55%) 0.0134\n",
      "0m 19s (60 60%) 0.0135\n",
      "0m 20s (65 65%) 0.0134\n",
      "0m 22s (70 70%) 0.0133\n",
      "0m 24s (75 75%) 0.0134\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(num_chars, 128, num_chars)\n",
    "\n",
    "n_iters = 100\n",
    "print_every = 5\n",
    "plot_every = 5\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "\tindex_in_data = iter % len(X)\n",
    "\toutput, loss = train(X[index_in_data], Y[index_in_data])\n",
    "\ttotal_loss += loss\n",
    "\n",
    "\tif iter % print_every == 0:\n",
    "\t    print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "\tif iter % plot_every == 0:\n",
    "\t    all_losses.append(total_loss / plot_every)\n",
    "\t    total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
