{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is meant to train RNNs with GAN implementation\n",
    "\n",
    "\n",
    "\n",
    "*********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief architecture and input/output abstract\n",
    "\n",
    "### Generator :\n",
    "\n",
    "    The Generator takes a sequence from the database of size sequence_length_in, this sequence goes to a RNN (rnn, lstm or gru), then, the last hidden_state of the rnn goes to a fully connected (linear) layer that generates one chord. This chord is added to the sequence, while the first chord of the sequence is removed. We then repeat this process until we generate a new sequence of length sequence_length_out.\n",
    "    \n",
    "### Discriminator :\n",
    "\n",
    "    The Discriminator takes a sequence of chords ad its input, this sequence goes to a RNN, and ad before, the last layer of the hidden_state of the RNN is used as an input for a linear layer. This linear layer then outputs a scalar. The goal of the discriminator is to output 1 if the input data was from the dataset and 0 if it was generated by the generator. \n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note : This is not working yet, somehow the generator do not updates weights while training on the discriminator network\n",
    "\n",
    "\n",
    "#### Note2 : As it is still in development, some of the parameters bellow are useless and have not been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'print_every': 5,\n",
    "        'optimizer': \"SGD\",\n",
    "        'lossFunction': \"MSE\",\n",
    "        'model_type': \"gru\",\n",
    "        'alphabet': 'a0',\n",
    "        'sequence_lenght_in': 16, \n",
    "        'sequence_lenght_out': 16, \n",
    "        'using_cuda': True,\n",
    "        'batch_size': 256,\n",
    "        'shuffle': True, \n",
    "        'num_workers': 6,\n",
    "        'hidden_size_generator': 512,\n",
    "        'num_layers_generator': 2,\n",
    "        'dropout_generator': 0.01,\n",
    "        'learning_rate_generator': 5e-2, \n",
    "        'hidden_size_discriminator':512,\n",
    "        'num_layers_discriminator':2,\n",
    "        'dropout_discriminator': 0.01,\n",
    "        'learning_rate_discriminator': 5e-2, \n",
    "        'epochs': 50,\n",
    "        'use_Paul_distance': True}\n",
    "\n",
    "paramsGen = {\n",
    "        'print_every': 5,\n",
    "        'optimizer': \"SGD\",\n",
    "        'lossFunction': \"MSE\",\n",
    "        'model_type': \"gru\",\n",
    "        'alphabet': 'a0',\n",
    "        'sequence_lenght_in': 16, \n",
    "        'sequence_lenght_out': 16, \n",
    "        'using_cuda': True,\n",
    "        'batch_size': 128,\n",
    "        'shuffle': True, \n",
    "        'num_workers': 6,\n",
    "        'hidden_size_generator': 512,\n",
    "        'num_layers_generator': 2,\n",
    "        'dropout_generator': 0.01,\n",
    "        'learning_rate_generator': 1e-4, \n",
    "        'epochs': 50}\n",
    "\n",
    "paramsGenOnData = {\n",
    "        'print_every': 5,\n",
    "        'plot_every': 5,\n",
    "        'optimizer': \"SGD\",\n",
    "        'lossFunction': \"MSE\",\n",
    "        'model_type': \"gru\",\n",
    "        'alphabet': 'a0',\n",
    "        'sequence_lenght': 16, \n",
    "        'using_cuda': True,\n",
    "        'batch_size': 128,\n",
    "        'shuffle': True, \n",
    "        'num_workers': 6,\n",
    "        'hidden_size': 512,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.05,\n",
    "        'learning_rate': 5e-2, \n",
    "        'epochs': 50,\n",
    "        'use_Paul_distance': True}\n",
    "\n",
    "paramsDisInit = {\n",
    "        'input_size':25,\n",
    "        'hidden_size_discriminator':512,\n",
    "        'num_layers_discriminator':2,\n",
    "        'dropout_discriminator': 0.01}\n",
    "\n",
    "paramsDisOnGen = {\n",
    "        'print_every': 5,\n",
    "        'optimizer': \"SGD\",\n",
    "        'lossFunction': \"MSE\",\n",
    "        'model_type': \"gru\",\n",
    "        'alphabet': 'a0',\n",
    "        'sequence_lenght_in': 16, \n",
    "        'sequence_lenght_out': 16, \n",
    "        'using_cuda': True,\n",
    "        'batch_size': 128,\n",
    "        'shuffle': True, \n",
    "        'num_workers': 6,\n",
    "        'hidden_size_discriminator': 512,\n",
    "        'num_layers_discriminator': 2,\n",
    "        'dropout_discriminator': 0.01,\n",
    "        'learning_rate_discriminator': 5e-2, \n",
    "        'epochs': 50\n",
    "}\n",
    "\n",
    "paramsDisOnData = {\n",
    "        'print_every': 5,\n",
    "        'optimizer': \"SGD\",\n",
    "        'lossFunction': \"MSE\",\n",
    "        'model_type': \"gru\",\n",
    "        'alphabet': 'a0',\n",
    "        'sequence_lenght_in': 16, \n",
    "        'sequence_lenght_out': 16, \n",
    "        'using_cuda': True,\n",
    "        'batch_size': 128,\n",
    "        'shuffle': True, \n",
    "        'num_workers': 6,\n",
    "        'hidden_size_discriminator': 256,\n",
    "        'num_layers_discriminator': 2,\n",
    "        'dropout_discriminator': 0.01,\n",
    "        'learning_rate_discriminator': 5e-2, \n",
    "        'epochs': 50\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "from GruGanClass import MYGRU\n",
    "from RnnGanClass import MYRNN\n",
    "from LstmGanClass import MYLSTM\n",
    "from DiscriminatorClass import MYDis\n",
    "import torch\n",
    "import os\n",
    "from utilities import chordUtil\n",
    "from utilities.chordUtil import *\n",
    "from utilities import dataImport\n",
    "\n",
    "\n",
    "\n",
    "dropout_generator = params['dropout_generator']\n",
    "model_type = params['model_type']\n",
    "num_layers_generator = params['num_layers_generator']\n",
    "hidden_size_generator = params['hidden_size_generator']\n",
    "alphabet = params['alphabet']\n",
    "sequence_lenght_in = params['sequence_lenght_in']\n",
    "sequence_lenght_out = params['sequence_lenght_out']\n",
    "num_layers_discriminator = params['num_layers_discriminator']\n",
    "hidden_size_discriminator = params['hidden_size_discriminator']\n",
    "\n",
    "model_string_generator = \"models/\"+model_type+str(num_layers_generator)+\"layers\"+str(hidden_size_generator)+\"blocks\"+alphabet+\"alphabet\"+str(sequence_lenght_in)+\"lenSeq_in\"+str(sequence_lenght_out)+\"lenSeq_out.pt\"\n",
    "model_string_discriminator = \"models/\"+model_type+str(num_layers_discriminator)+\"layers\"+str(hidden_size_discriminator)+\"blocks\"+alphabet+\"alphabet\"+str(sequence_lenght_out)+\"lenSeq_out.pt\"\n",
    "\n",
    "# Getting alphabet size :\n",
    "rootname = \"inputs/jazz_xlab/\"\n",
    "filenames = os.listdir(rootname)\n",
    "dictChord, listChord = chordUtil.getDictChord(eval(alphabet))\n",
    "alphabet_size = len(dictChord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "{'G#:min': 0, 'G:maj': 1, 'E:min': 2, 'A:min': 3, 'A#:maj': 4, 'C:min': 5, 'D:maj': 6, 'D#:maj': 7, 'A:maj': 8, 'F#:maj': 9, 'C:maj': 10, 'C#:min': 11, 'G#:maj': 12, 'C#:maj': 13, 'G:min': 14, 'E:maj': 15, 'F#:min': 16, 'B:maj': 17, 'D:min': 18, 'B:min': 19, 'N': 20, 'D#:min': 21, 'A#:min': 22, 'F:maj': 23, 'F:min': 24}\n"
     ]
    }
   ],
   "source": [
    "rootname = \"inputs/jazz_xlab/\"\n",
    "filenames = os.listdir(rootname)\n",
    "dictChord, listChord = chordUtil.getDictChord(eval(alphabet))\n",
    "print(len(dictChord))\n",
    "print(dictChord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising the networks with user's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"gru\":\n",
    "    myGenerator = MYGRU(alphabet_size, hidden_size_generator, num_layers_generator, dropout_generator)\n",
    "elif model_type == \"lstm\":\n",
    "    myGenerator = MYLSTM(alphabet_size, hidden_size_generator, num_layers_generator, dropout_generator)\n",
    "elif model_type == \"rnn\":\n",
    "    myGenerator = MYRNN(alphabet_size, hidden_size_generator, num_layers_generator, dropout_generator)\n",
    "#TODO making the user choose between  gru, lstm and rnn in the parameters\n",
    "myDis = MYDis(**paramsDisInit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic training of the generator on Data\n",
    "\n",
    "### Note : actually this part is not a part of the GAN, but it can be usefull to have a generator somewhat trained in order to train the discriminator correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "Train : 0m 2s (2 20%) loss : 0.4868, accuracy : 12.1336%\n",
      "Test : 0m 3s (2 20%) loss : 0.1460, accuracy : 14.8269%\n",
      "Train : 0m 5s (4 40%) loss : 0.4322, accuracy : 14.8593%\n",
      "Test : 0m 6s (4 40%) loss : 0.1460, accuracy : 16.8590%\n",
      "Train : 0m 8s (6 60%) loss : 0.4883, accuracy : 21.2192%\n",
      "Test : 0m 9s (6 60%) loss : 0.1460, accuracy : 19.2173%\n",
      "Train : 0m 11s (8 80%) loss : 0.5207, accuracy : 20.7503%\n",
      "Test : 0m 12s (8 80%) loss : 0.1460, accuracy : 19.8695%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "paramsGenOnData['epochs']=10\n",
    "paramsGenOnData['print_every']=2\n",
    "myGenerator.trainAndTest(**paramsGenOnData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try training the generator to fool the discriminator\n",
    "\n",
    "## Problem here !\n",
    "### Generator does not train :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "genWin : 0m 15s (1 20%) loss : 0.7583, accuracy : 0.0000%\n",
      "genWin : 0m 22s (2 40%) loss : 0.7581, accuracy : 0.0000%\n",
      "genWin : 0m 30s (3 60%) loss : 0.7582, accuracy : 0.0000%\n",
      "genWin : 0m 37s (4 80%) loss : 0.7584, accuracy : 0.0000%\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsGen['epochs']=5\n",
    "paramsGen['print_every']=1\n",
    "paramsGen['learning_rate_generator']=1e-2\n",
    "paramsGen['dropout_generator']=0.1\n",
    "paramsGen['disNet']=myDis\n",
    "\n",
    "myGenerator.trainOnDis(**paramsGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the discriminator to recognize fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 13s (1 20%) loss : 0.0008, accuracy : 100.0000%\n",
      "disOnGen : 0m 20s (2 40%) loss : 0.0008, accuracy : 100.0000%\n",
      "disOnGen : 0m 27s (3 60%) loss : 0.0008, accuracy : 100.0000%\n",
      "disOnGen : 0m 34s (4 80%) loss : 0.0008, accuracy : 100.0000%\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsDisOnGen['epochs']=5\n",
    "paramsDisOnGen['print_every']=1\n",
    "paramsDisOnGen['learning_rate_discriminator']=5e-5\n",
    "paramsDisOnGen['dropout_discriminator']=0.1\n",
    "paramsDisOnGen['genNet']=myGenerator\n",
    "\n",
    "myDis.trainOnGen(**paramsDisOnGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the discriminator to recognize real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 20%) loss : 0.7600, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 3s (2 40%) loss : 0.7550, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 4s (3 60%) loss : 0.7515, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 5s (4 80%) loss : 0.7482, accuracy : 0.0000%\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsDisOnData['epochs']=5\n",
    "paramsDisOnData['print_every']=1\n",
    "paramsDisOnData['learning_rate_discriminator']=2e-5\n",
    "paramsDisOnData['dropout_discriminator']=0.1\n",
    "\n",
    "myDis.trainOnData(**paramsDisOnData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the discriminator on Real and Fake Data\n",
    "## Also using more real data or more fake data dependinig on its weak points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration: 0\n",
      "\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 13s (1 50%) loss : 0.0014, accuracy : 100.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 14%) loss : 0.7437, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 3s (2 28%) loss : 0.7391, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 4s (3 42%) loss : 0.7360, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 6s (4 57%) loss : 0.7326, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 7s (5 71%) loss : 0.7292, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 8s (6 85%) loss : 0.7257, accuracy : 0.0000%\n",
      "Finished Training\n",
      "\n",
      "iteration: 1\n",
      "\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 13s (1 50%) loss : 0.0025, accuracy : 100.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 14%) loss : 0.7216, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 3s (2 28%) loss : 0.7170, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 4s (3 42%) loss : 0.7137, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 5s (4 57%) loss : 0.7100, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 6s (5 71%) loss : 0.7071, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 7s (6 85%) loss : 0.7037, accuracy : 0.0000%\n",
      "Finished Training\n",
      "\n",
      "iteration: 2\n",
      "\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 13s (1 50%) loss : 0.0040, accuracy : 100.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 14%) loss : 0.7002, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 3s (2 28%) loss : 0.6955, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 4s (3 42%) loss : 0.6922, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 5s (4 57%) loss : 0.6889, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 6s (5 71%) loss : 0.6859, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 7s (6 85%) loss : 0.6829, accuracy : 0.0000%\n",
      "Finished Training\n",
      "\n",
      "iteration: 3\n",
      "\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 13s (1 50%) loss : 0.0057, accuracy : 100.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 14%) loss : 0.6797, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 3s (2 28%) loss : 0.6751, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 4s (3 42%) loss : 0.6719, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 5s (4 57%) loss : 0.6691, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 6s (5 71%) loss : 0.6658, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 7s (6 85%) loss : 0.6629, accuracy : 0.0000%\n",
      "Finished Training\n",
      "\n",
      "iteration: 4\n",
      "\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 12s (1 50%) loss : 0.0077, accuracy : 100.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 14%) loss : 0.6598, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 3s (2 28%) loss : 0.6553, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 4s (3 42%) loss : 0.6526, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 5s (4 57%) loss : 0.6496, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 6s (5 71%) loss : 0.6465, accuracy : 0.0000%\n",
      "disOnDataWin : 0m 7s (6 85%) loss : 0.6433, accuracy : 0.0000%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train discriminator\n",
    "disOnGenWin = 1\n",
    "disOnDataWin = 1\n",
    "metaEpochs = 5\n",
    "paramsDisOnGen['epochs']=2\n",
    "paramsDisOnData['epochs']=2\n",
    "\n",
    "for i in range(metaEpochs):\n",
    "    print(\"\\niteration: %d\\n\" % i)\n",
    "    if disOnDataWin>0.75 or disOnDataWin>disOnGenWin:\n",
    "        paramsDisOnGen['epochs']=4\n",
    "        paramsDisOnData['epochs']=4\n",
    "\n",
    "    if disOnGenWin>0.75 or disOnGenWin>disOnDataWin:\n",
    "        paramsDisOnGen['epochs']=2\n",
    "        paramsDisOnData['epochs']=7\n",
    "        \n",
    "    disOnGenWin = max(myDis.trainOnGen(**paramsDisOnGen))\n",
    "    disOnDataWin = max(myDis.trainOnData(**paramsDisOnData))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train both generator and discriminator\n",
    "## note : this algorithm is certainly really bad, as the generator does not train well for now, I cannot improve it efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnGen : 0m 13s (1 50%) loss : 0.0099, accuracy : 100.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 50%) loss : 0.6410, accuracy : 0.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 50%) loss : 0.6353, accuracy : 0.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 50%) loss : 0.6292, accuracy : 0.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 50%) loss : 0.6234, accuracy : 0.0000%\n",
      "Finished Training\n",
      "Trying using Cuda ...\n",
      "OK\n",
      "Start training\n",
      "disOnDataWin : 0m 2s (1 50%) loss : 0.6177, accuracy : 0.0000%\n",
      "Finished Training\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Train Global\n",
    "paramsGen['epochs']=2\n",
    "paramsDisOnGen['epochs']=2\n",
    "paramsDisOnData['epochs']=2\n",
    "\n",
    "metaEpochs = 5\n",
    "\n",
    "genWin = 0\n",
    "disOnGenWin = 0\n",
    "disOnDataWin = 0\n",
    "\n",
    "for i in range(metaEpochs):\n",
    "    if disOnGenWin < 0.75:\n",
    "        disOnGenWin = max(myDis.trainOnGen(**paramsDisOnGen))\n",
    "    if disOnDataWin < 0.75:\n",
    "        disOnDataWin = max(myDis.trainOnData(**paramsDisOnData))\n",
    "    else:\n",
    "        genWin = max(myGenerator.trainOnDis(**paramsGen))\n",
    "\n",
    "print(\"finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the generator on some simple chord sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n",
      "['C:maj', 'F:maj', 'C:maj', 'C:maj']\n",
      "['F:maj', 'F:maj', 'C:maj', 'C:maj']\n",
      "['G:maj', 'F:maj', 'C:maj', 'G:maj']\n",
      "['C:maj', 'C:maj', 'F:maj', 'G:maj']\n",
      "generated :\n",
      "['E:maj', 'C#:maj', 'A:maj', 'N']\n",
      "['F:min', 'F:maj', 'C#:maj', 'D#:maj']\n",
      "['F:min', 'A#:maj', 'C:maj', 'G#:maj']\n",
      "['A#:min', 'B:maj', 'E:min', 'G#:min']\n",
      "['D:maj', 'A#:min', 'F:maj', 'B:min']\n",
      "['E:min', 'A:maj', 'D:maj', 'C#:min']\n",
      "['F:min', 'F#:min', 'A:min', 'F#:maj']\n",
      "['G#:min', 'C#:maj', 'C:maj', 'F#:min']\n",
      "['D:min', 'E:min', 'E:min', 'C:min']\n",
      "['D#:min', 'A#:maj', 'D:min', 'G:min']\n",
      "['E:maj', 'F#:min', 'A#:min', 'G:maj']\n",
      "['F#:maj', 'G#:maj', 'G:min', 'E:min']\n"
     ]
    }
   ],
   "source": [
    "test_sequence = [\"C:maj\",\"F:maj\",\"C:maj\",\"C:maj\",\n",
    "                 \"F:maj\",\"F:maj\",\"C:maj\",\"C:maj\",\n",
    "                 \"G:maj\",\"F:maj\",\"C:maj\",\"G:maj\",\n",
    "                 \"C:maj\",\"C:maj\",\"F:maj\",\"G:maj\"]\n",
    "myGenerator.generateFromSequence(test_sequence, generation_lenght=64,\n",
    "                               alphabet = 'a0',sampling=True, \n",
    "                               using_cuda=True, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if the discriminator tells that the test sequence is real or false (1 is true and 0 is false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying using Cuda ...\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1244]], device='cuda:0', grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using_cuda = True\n",
    "# Cuda blabla\n",
    "if using_cuda:\n",
    "    print(\"Trying using Cuda ...\")\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        print(\"OK\")\n",
    "    else:\n",
    "        print(\"Woops, Cuda cannot be found :'( \")\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using Cpu\")\n",
    "\n",
    "lenSeq = len(test_sequence)\n",
    "\n",
    "\n",
    "# Getting chords dictionary\n",
    "rootname = \"inputs/jazz_xlab/\"\n",
    "filenames = os.listdir(rootname)\n",
    "dictChord, listChord = chordUtil.getDictChord(eval(alphabet))\n",
    "\n",
    "\n",
    "# Initialising objects\n",
    "test_sequence_tensor = torch.zeros(1, len(test_sequence), len(dictChord)).to(device)\n",
    "last_chords_output = torch.zeros(1, lenSeq, len(dictChord)).to(device)\n",
    "test_sequence_tensor.requires_grad = False\n",
    "last_chords_output.requires_grad = False\n",
    "for t in range(len(test_sequence)):\n",
    "    test_sequence_tensor[0, t, dictChord[test_sequence[t]]] = 1\n",
    "    \n",
    "\n",
    "myDis(test_sequence_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
