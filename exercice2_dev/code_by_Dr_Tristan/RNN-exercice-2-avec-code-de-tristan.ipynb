{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Petite implémentation d'un RNN tout simple pour tester les fonctions d'importation de la Base de données faites par Tristan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from random import randint\n",
                "from utilities import chordUtil\n",
                "from utilities import dataImport\n",
                "from utilities.chordUtil import *\n",
                "from utilities.dataImport import *\n",
                "from sklearn.model_selection import train_test_split\n",
                "import os\n",
                "import numpy as np\n",
                "import random\n",
                "import sys\n",
                "import torch.nn as nn\n",
                "import time\n",
                "import math\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.ticker as ticker"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def timeSince(since):\n",
                "    now = time.time()\n",
                "    s = now - since\n",
                "    m = math.floor(s / 60)\n",
                "    s -= m * 60\n",
                "    return '%dm %ds' % (m, s)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "use_cuda\n",
                        "True\n"
                    ]
                }
            ],
            "source": [
                "# CUDA for PyTorch\n",
                "use_cuda = torch.cuda.is_available()\n",
                "print(\"use_cuda\")\n",
                "print(use_cuda)\n",
                "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "37\n",
                        "{'G#:maj': 0, 'A#:maj': 1, 'A:min': 2, 'D:maj': 3, 'F#:dim': 4, 'C#:dim': 5, 'B:maj': 6, 'F:min': 7, 'E:min': 8, 'B:min': 9, 'C:min': 10, 'F:dim': 11, 'A#:min': 12, 'D#:maj': 13, 'D:dim': 14, 'G#:min': 15, 'C#:maj': 16, 'A:dim': 17, 'F:maj': 18, 'A#:dim': 19, 'F#:min': 20, 'G:maj': 21, 'D#:dim': 22, 'N': 23, 'C:dim': 24, 'A:maj': 25, 'E:dim': 26, 'G:min': 27, 'F#:maj': 28, 'E:maj': 29, 'B:dim': 30, 'D#:min': 31, 'G:dim': 32, 'D:min': 33, 'C:maj': 34, 'G#:dim': 35, 'C#:min': 36}\n"
                    ]
                }
            ],
            "source": [
                "# Init\n",
                "lenSeq = 16\n",
                "alpha = 'a1'\n",
                "rootname = \"inputs/jazz_xlab/\"\n",
                "filenames = os.listdir(rootname)\n",
                "#filenames.remove(\".DS_Store\")\n",
                "dictChord, listChord = chordUtil.getDictChord(eval(alpha))\n",
                "print(len(dictChord))\n",
                "print(dictChord)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create datasets\n",
                "files_train ,files_test = train_test_split(filenames,test_size=0.7)\n",
                "dataset_train = dataImport.ChordSeqDataset(files_train, rootname, alpha, dictChord, lenSeq)\n",
                "dataset_test = dataImport.ChordSeqDataset(files_test, rootname, alpha, dictChord, lenSeq)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create generators\n",
                "params = {'batch_size': 64,\n",
                "          'shuffle': True,\n",
                "          'num_workers': 6}\n",
                "training_generator = data.DataLoader(dataset_train, **params)\n",
                "testing_generator = data.DataLoader(dataset_test, **params)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RNN(nn.Module):\n",
                "    def __init__(self, input_size, hidden_size, output_size):\n",
                "        super(RNN, self).__init__()\n",
                "        self.hidden_size = hidden_size\n",
                "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
                "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
                "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
                "        self.dropout = nn.Dropout(0.1)\n",
                "        self.softmax = nn.LogSoftmax(dim=0)\n",
                "\n",
                "    def forward(self, input, hidden):\n",
                "        input_combined = torch.cat((input, hidden), 0)\n",
                "        hidden = self.i2h(input_combined)\n",
                "        output = self.i2o(input_combined)\n",
                "        output_combined = torch.cat((hidden, output), 0)\n",
                "        output = self.o2o(output_combined)\n",
                "        output = self.dropout(output)\n",
                "        output = self.softmax(output)\n",
                "        return output, hidden\n",
                "\n",
                "    def initHidden(self):\n",
                "        return torch.zeros(self.hidden_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train(local_batch, local_labels):\n",
                "    hidden = rnn.initHidden()\n",
                "\n",
                "    rnn.zero_grad()\n",
                "\n",
                "    loss = 0\n",
                "    #print(local_batch[0])\n",
                "    #print(local_batch.size())\n",
                "    #print(local_labels[0])\n",
                "    #print(local_labels.size())\n",
                "    # parcourir le mini batc\n",
                "    for i in range(len(local_batch)):\n",
                "        hidden = rnn.initHidden()\n",
                "        # parcourir la sequence\n",
                "        for j in range(len(local_batch[i])):      \n",
                "            output, hidden = rnn(local_batch[i][j], hidden)\n",
                "            \n",
                "        #print(output)\n",
                "        #print(local_labels[i])\n",
                "        #l = criterion(output, torch.tensor([torch.argmax(local_labels[i])]))\n",
                "        #l = criterion(output, local_labels[i])\n",
                "        l = criterion(torch.reshape(output,(1, len(output))), torch.tensor([torch.argmax(local_labels[i])]))\n",
                "        loss += l\n",
                "\n",
                "    loss.backward()\n",
                "\n",
                "    for p in rnn.parameters():\n",
                "        p.data.add_(-learning_rate, p.grad.data)\n",
                "\n",
                "    return output, loss.item() / len(local_batch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "Expected a Tensor of type torch.cuda.FloatTensor but found a type torch.FloatTensor for sequence element 1 in sequence argument at position #1 'tensors'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-12-bf36792bc7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<ipython-input-10-3ed9dd77c8a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(local_batch, local_labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# parcourir la sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<ipython-input-7-e701d35b7f71>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0minput_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: Expected a Tensor of type torch.cuda.FloatTensor but found a type torch.FloatTensor for sequence element 1 in sequence argument at position #1 'tensors'"
                    ]
                }
            ],
            "source": [
                "rnn = RNN(len(dictChord), 128, len(dictChord))\n",
                "\n",
                "plot_every = 1\n",
                "all_losses = []\n",
                "total_loss = 0 # Reset every plot_every iters\n",
                "start = time.time()\n",
                "criterion = nn.NLLLoss()\n",
                "learning_rate = 0.0005\n",
                "print_every = 1\n",
                "max_epochs = 20\n",
                "\n",
                "\n",
                "# Begin training\n",
                "\n",
                "for epoch in range(1, max_epochs):\n",
                "    # Training\n",
                "    for local_batch, local_labels in training_generator:\n",
                "        # Transfer to GPU\n",
                "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
                "        \n",
                "        output, loss = train(local_batch, local_labels)\n",
                "        total_loss += loss\n",
                "\n",
                "    if epoch % print_every == 0:\n",
                "        print('%s (%d %d%%) %.4f' % (timeSince(start), epoch, epoch / max_epochs * 100, loss))\n",
                "\n",
                "    if epoch % plot_every == 0:\n",
                "        all_losses.append(total_loss / (plot_every * len(local_batch)))\n",
                "        total_loss = 0\n",
                "        \n",
                "\n",
                "    # Testing\n",
                "    #for local_batch, local_labels in testing_generator:\n",
                "        # Transfer to GPU\n",
                "        #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
                "\n",
                "        # //// Test the model  ////\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure()\n",
                "plt.plot(all_losses)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_sequence = [\"C:maj\",\"F:maj\",\"C:maj\",\"C:maj\",\"F:maj\",\"F:maj\",\"C:maj\",\"C:maj\",\"G:maj\",\"F:maj\"]\n",
                "\n",
                "test_sequence_tensor = torch.zeros(len(test_sequence), len(dictChord))\n",
                "for t in range(len(test_sequence)):\n",
                "    test_sequence_tensor[t, dictChord[test_sequence[t]]] = 1\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['C:maj', 'F:maj', 'C:maj', 'C:maj', 'F:maj', 'F:maj', 'C:maj', 'C:maj']\n",
                        "['G:maj', 'F:maj', 'F:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['F:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'F:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'F:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'F:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n",
                        "['C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj', 'C:maj']\n"
                    ]
                }
            ],
            "source": [
                "hidden = rnn.initHidden()\n",
                "generation_lenght = 120\n",
                "\n",
                "generated_sequence = [0 for i in range(generation_lenght)]\n",
                "\n",
                "for t in range(generation_lenght):\n",
                "    if t < len(test_sequence):\n",
                "        output, hidden = rnn(test_sequence_tensor[t], hidden)\n",
                "        generated_sequence[t] = test_sequence[t]\n",
                "    else : \n",
                "        last_chord_output = torch.zeros(len(dictChord))\n",
                "        last_chord_output[torch.argmax(output).item()]\n",
                "        output, hidden = rnn(last_chord_output, hidden)\n",
                "        generated_sequence[t] = listChord[torch.argmax(output).item()]\n",
                "\n",
                "        \n",
                "for i in range(generation_lenght):\n",
                "    if i%8 == 0:\n",
                "        print(generated_sequence[i:i+8])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
